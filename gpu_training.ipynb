{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f656fc-2f24-4ac8-b273-ef6b5a6f2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from helpers import sample_batch, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fccc8f-e7e6-4fce-bd9d-070215a83e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model, filename):\n",
    "    N = 5_000\n",
    "    x0= sample_batch(N)\n",
    "    samples = model.sample(N)\n",
    "    \n",
    "    fontsize=22\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 6))\n",
    "    # Common x and y limits\n",
    "    x_limits = (-2, 2)\n",
    "    y_limits = (-2, 2)\n",
    "    \n",
    "    data = [\n",
    "            [x0, model.forward_process(x0, 20)[-1], model.forward_process(x0, 40)[-1]],\n",
    "            [samples[0], samples[20], samples[40]]\n",
    "           ]\n",
    "    titles = ['t=0','t=T/2', 't=T']\n",
    "    \n",
    "    for i in range(nrows):  # Iterate over rows\n",
    "        for j in range(ncols):  # Iterate over columns\n",
    "            colour = \"b\" if i == 0 else \"r\"\n",
    "            if i == 0 and j == 0:\n",
    "                ax[i,j].set_ylabel(r\"$q\\mathbf{x}^{(0..T)})$\")\n",
    "            if i == 1 and j == 0:\n",
    "                ax[i,j].set_ylabel(r\"$p\\mathbf{x}^{(0..T)})$\")\n",
    "            ax[i,j].scatter(data[i][j][:, 0].data.numpy(), data[i][j][:, 1].data.numpy(), alpha=0.1, c= colour, s=4)\n",
    "            ax[i,j].set_title(titles[j])\n",
    "            ax[i,j].set_xlim(x_limits)\n",
    "            ax[i,j].set_ylim(y_limits)\n",
    "            plt.gca().set_aspect(\"equal\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74aa1234-38cf-4d86-954b-da1b9ec484ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel():\n",
    "    def __init__(self, T, model: nn.Module, dim=2):\n",
    "        self.betas = torch.sigmoid(torch.linspace(-18, 10, T)) * (3e-1 - 1e-5) + 1e-5\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_bar = torch.cumprod(self.alphas, dim=0)\n",
    "        self.T = T\n",
    "        self.model = model\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward_process(self, x0, t):\n",
    "        \"\"\"\n",
    "        param t: number of diffusion steps\n",
    "        \"\"\"\n",
    "        assert t > 0, \"should be greater than zero\"\n",
    "        t <= self.T, f\"t should be lower or equal than {self.T}\" \n",
    "        \n",
    "        t = t - 1 # index start at zero\n",
    "        mu = torch.sqrt(self.alphas_bar[t]) * x0\n",
    "        std = torch.sqrt(1 - self.alphas_bar[t])\n",
    "        epsilon = torch.randn_like(x0)\n",
    "        xt = mu + epsilon * std  # data ~ N(mu, std)\n",
    "\n",
    "        m1 = torch.sqrt(self.alphas_bar[t-1]) * self.betas[t] / (1 - self.alphas_bar[t])\n",
    "        m2 = torch.sqrt(self.alphas[t]) * (1-self.alphas_bar[t-1]) / (1 - self.alphas_bar[t])\n",
    "        mu_q = m1 * x0 + m2 * xt\n",
    "        std_q = torch.sqrt( (1-self.alphas_bar[t-1]) / (1-self.alphas_bar[t]) * self.betas[t] )\n",
    "        \n",
    "        return mu_q, std_q, xt\n",
    "\n",
    "    def reverse_process(self, xt, t):\n",
    "        assert t > 0, \"should be greater than zero\"\n",
    "        t <= self.T, f\"t should be lower or equal than {self.T}\"\n",
    "\n",
    "        t = t - 1 # index start at zero\n",
    "        mu, std = self.model(xt, t)\n",
    "        epsilon = torch.randn_like(xt)\n",
    "        return  mu, std, mu + epsilon * std # data ~ N(mu, std)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        noise = torch.randn(batch_size, self.dim)\n",
    "        x = noise\n",
    "\n",
    "        # adding the starting noise already makes the list composed of 41 elements (like in the paper)\n",
    "        samples = [x]\n",
    "        for t in range(self.T, 0, -1):\n",
    "            # Edge effect of diffusione model (in the last step don't do anything)\n",
    "            if not (t == 1):\n",
    "                _, _, x = self.reverse_process(x, t)\n",
    "            samples.append(x)\n",
    "\n",
    "        return samples[:: -1] # reverse results in the list\n",
    "\n",
    "    def get_loss(self, x0):\n",
    "        \"\"\"\n",
    "        param x0: batch [batch_size, self.dim]\n",
    "        \"\"\"\n",
    "        # sample t\n",
    "        t = torch.randint(2, 40+1, (1,))\n",
    "        mu_q , sigma_q, xt = self.forward_process(x0, t)\n",
    "        mu_p, sigma_p,  xt_minus1 = self.reverse_process(xt.float(), t)\n",
    "        # KL divergence for two gaussian distribution KL(q||p)\n",
    "        KL = torch.log(sigma_p) -  torch.log(sigma_q) + (sigma_q**2 + (mu_q - mu_p)**2) / (2 * sigma_p**2)\n",
    "        K_prime = - KL.mean() # we want to maximize K\n",
    "        loss = -K_prime # should be minimized\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace55065-65a4-49fb-bf87-60b7e7eeb105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(diffusion_model, optimizer, batch_size, epochs):\n",
    "\n",
    "    training_loss = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        xO = sample_batch(batch_size)\n",
    "        loss = diffusion_model.get_loss(xO)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss.append(loss.item())\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            plt.plot(training_loss)\n",
    "            plt.savefig(f\"train_loss_epoch_{epoch}.png\")\n",
    "            plt.show()\n",
    "            plot(diffusion_model, f\"./train_images/train_epoch_{epoch}.png\")\n",
    "    \n",
    "    return training_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
